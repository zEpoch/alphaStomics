# AlphaSTomics - ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [è®­ç»ƒæ–¹å¼å¯¹æ¯”](#è®­ç»ƒæ–¹å¼å¯¹æ¯”)
3. [é«˜çº§ç‰¹æ€§](#é«˜çº§ç‰¹æ€§)
4. [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
5. [å·¥å…·è„šæœ¬](#å·¥å…·è„šæœ¬)
6. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone <repository_url>
cd alphaStomics

# å®‰è£…ä¾èµ–
pip install torch pytorch-lightning pyyaml wandb scanpy anndata pyarrow
pip install -e .
```

### éªŒè¯å®‰è£…

```bash
python -c "from alphastomics.diffusion_model import MaskedDiffusionModule; print('âœ“ å®‰è£…æˆåŠŸ')"
```

### ç¬¬ä¸€æ¬¡è®­ç»ƒ

```bash
# ä½¿ç”¨ç‹¬ç«‹è„šæœ¬
python train.py \
    --config config.yaml \
    --data_dir ./processed_data \
    --num_genes 2000 \
    --exp_name my_first_experiment

# æˆ–ä½¿ç”¨æ¨¡å—åŒ–æ¥å£
python -m alphastomics.main train \
    --config config.yaml \
    --data_dir ./processed_data
```

---

## ğŸ“Š è®­ç»ƒæ–¹å¼å¯¹æ¯”

AlphaSTomics æä¾›ä¸¤ç§è®­ç»ƒæ–¹å¼ï¼ŒåŠŸèƒ½å®Œå…¨ç›¸åŒï¼Œå¯æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©ï¼š

### æ–¹å¼ 1: `train.py` ï¼ˆç‹¬ç«‹è„šæœ¬ï¼‰

**ä¼˜åŠ¿ï¼š**
- âœ… ç®€å•ç›´è§‚ï¼Œå‚æ•°æ¸…æ™°
- âœ… é€‚åˆå¿«é€Ÿå®éªŒå’ŒåŸå‹å¼€å‘
- âœ… è¾“å‡ºç»“æ„æ¸…æ™°ï¼ˆ`outputs/<exp_name>/`ï¼‰
- âœ… éœ€è¦æŒ‡å®šå®éªŒåç§°ï¼Œä¾¿äºç®¡ç†

**ä½¿ç”¨åœºæ™¯ï¼š**
- ç ”ç©¶å’Œå®éªŒ
- å‚æ•°è°ƒä¼˜
- å¿«é€Ÿæµ‹è¯•æ–°æƒ³æ³•

**ç¤ºä¾‹ï¼š**
```bash
python train.py \
    --config config.yaml \
    --data_dir ./data \
    --num_genes 2000 \
    --use_gated_attention \
    --use_moe --num_experts 4 --moe_top_k 2 \
    --exp_name my_experiment
```

### æ–¹å¼ 2: `python -m alphastomics.main train` ï¼ˆæ¨¡å—åŒ–ï¼‰

**ä¼˜åŠ¿ï¼š**
- âœ… é›†æˆåˆ°å®Œæ•´æµæ°´çº¿ä¸­
- âœ… æ”¯æŒå¤šä¸ªå­å‘½ä»¤ï¼ˆpreprocess, train, test, sampleï¼‰
- âœ… é€‚åˆç”Ÿäº§ç¯å¢ƒ
- âœ… æ›´å¥½çš„ä»£ç ç»„ç»‡

**ä½¿ç”¨åœºæ™¯ï¼š**
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- è‡ªåŠ¨åŒ–æµæ°´çº¿
- é›†æˆåˆ°æ›´å¤§çš„ç³»ç»Ÿä¸­

**ç¤ºä¾‹ï¼š**
```bash
# é¢„å¤„ç†
python -m alphastomics.main preprocess --raw_dir ./raw --output_dir ./processed

# è®­ç»ƒ
python -m alphastomics.main train \
    --config config.yaml \
    --use_gated_attention \
    --use_moe --num_experts 4 --moe_top_k 2

# æµ‹è¯•
python -m alphastomics.main test --config config.yaml --checkpoint best.ckpt

# é‡‡æ ·
python -m alphastomics.main sample --checkpoint best.ckpt --num_samples 1000
```

### å‚æ•°å¯¹æ¯”

| ç‰¹æ€§ | train.py | main.py train |
|------|----------|--------------|
| Gated Attention | âœ… | âœ… |
| MoE | âœ… | âœ… |
| Masked Diffusion | âœ… | âœ… |
| è‡ªå®šä¹‰å®éªŒå | å¿…éœ€ `--exp_name` | ä»é…ç½®æ¨æ–­ |
| è¾“å‡ºç›®å½• | `outputs/<exp_name>/` | é…ç½®æ–‡ä»¶æŒ‡å®š |
| å­å‘½ä»¤æ”¯æŒ | âŒ ä»…è®­ç»ƒ | âœ… å®Œæ•´æµæ°´çº¿ |
| å‚æ•°è¦†ç›– | âœ… | âœ… |

---

## ğŸ¯ é«˜çº§ç‰¹æ€§

### 1. Gated Attention

**ä½œç”¨ï¼š** é€šè¿‡é—¨æ§æœºåˆ¶è°ƒèŠ‚æ³¨æ„åŠ›å¼ºåº¦ï¼Œæå‡æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚

**å‚æ•°ï¼š**
- `--use_gated_attention`: å¯ç”¨ Gated Attention
- `--gate_type {headwise,elementwise}`: é—¨æ§ç±»å‹
  - `headwise`: æ¯ä¸ªæ³¨æ„åŠ›å¤´å…±äº«ä¸€ä¸ªé—¨æ§å€¼ï¼ˆå‚æ•°æ›´å°‘ï¼‰
  - `elementwise`: æ¯ä¸ªä½ç½®ç‹¬ç«‹é—¨æ§å€¼ï¼ˆè¡¨è¾¾èƒ½åŠ›æ›´å¼ºï¼‰

**ç¤ºä¾‹ï¼š**
```bash
# Elementwise gatingï¼ˆé»˜è®¤ï¼Œæ€§èƒ½æœ€å¼ºï¼‰
python train.py --config config.yaml --use_gated_attention ...

# Headwise gatingï¼ˆå‚æ•°å°‘ï¼‰
python train.py --config config.yaml --use_gated_attention --gate_type headwise ...
```

**å‚æ•°å½±å“ï¼š**
- Elementwiseï¼ˆé»˜è®¤ï¼‰: å¢åŠ æ›´å¤šå‚æ•°ï¼Œä½†æ€§èƒ½æœ€å¼º
- Headwise: å¢åŠ  ~13K å‚æ•°ï¼ˆçº¦ 1.9%ï¼‰ï¼Œå‚æ•°æ›´å°‘

### 2. Mixture of Experts (MoE)

**ä½œç”¨ï¼š** ä½¿ç”¨å¤šä¸ªä¸“å®¶ç½‘ç»œï¼Œæ¯æ¬¡åªæ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼Œæå‡å‚æ•°æ•ˆç‡ã€‚

**å‚æ•°ï¼š**
- `--use_moe`: å¯ç”¨ MoE
- `--num_experts <int>`: ä¸“å®¶æ€»æ•°ï¼ˆæ¨èï¼š4, 8, 16ï¼‰
- `--moe_top_k <int>`: æ¯æ¬¡æ¿€æ´»çš„ä¸“å®¶æ•°ï¼ˆæ¨èï¼š2ï¼‰

**ç¤ºä¾‹ï¼š**
```bash
# 4 é€‰ 2
python train.py --config config.yaml --use_moe --num_experts 4 --moe_top_k 2 ...

# 8 é€‰ 2
python train.py --config config.yaml --use_moe --num_experts 8 --moe_top_k 2 ...
```

**å‚æ•°æ•ˆç‡ï¼š**

| é…ç½® | æ€»å‚æ•° | æ¿€æ´»å‚æ•° | æ¿€æ´»ç‡ |
|------|--------|---------|--------|
| Dense | 695K | 695K | 100% |
| MoE 4é€‰2 | 710K | 644K | 90.7% |
| MoE 8é€‰2 | 725K | 605K | 83.5% |

**å…³é”®è§è§£ï¼š**
- æ€»å‚æ•°é‡ç•¥å¢ï¼ˆ~2%ï¼‰ï¼Œå› ä¸ºéœ€è¦è·¯ç”±ç½‘ç»œ
- æ¿€æ´»å‚æ•°æ˜¾è‘—å‡å°‘ï¼ˆ4é€‰2 çº¦ 50%ï¼‰
- FFN å±‚æ¿€æ´»ç‡ = top_k / num_experts
- æ•´ä½“æ¨¡å‹æ¿€æ´»ç‡è¾ƒé«˜ï¼Œå› ä¸ºå…¶ä»–å±‚ï¼ˆembedding, attentionï¼‰100% æ¿€æ´»

### 3. Masked Diffusion

**ä½œç”¨ï¼š** åœ¨è®­ç»ƒæ—¶éšæœºé®ç½©éƒ¨åˆ†ç‰¹å¾ï¼Œå¢å¼ºæ¨¡å‹é²æ£’æ€§ã€‚

**å‚æ•°ï¼š**
- `--enable_masking`: å¯ç”¨é®ç½©
- `--expression_mask_ratio <float>`: è¡¨è¾¾é‡é®ç½©æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰
- `--position_mask_ratio <float>`: ä½ç½®é®ç½©æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰

**ç¤ºä¾‹ï¼š**
```bash
python train.py \
    --config config.yaml \
    --enable_masking \
    --expression_mask_ratio 0.3 \
    --position_mask_ratio 0.33 \
    ...
```

### 4. ç»„åˆä½¿ç”¨

**æœ€å¼ºé…ç½®ï¼š** Gated Attention + MoE + Masked Diffusion

```bash
python train.py \
    --config config.yaml \
    --data_dir ./data \
    --num_genes 2000 \
    --use_gated_attention \
    --gate_type elementwise \
    --use_moe \
    --num_experts 8 \
    --moe_top_k 2 \
    --enable_masking \
    --expression_mask_ratio 0.3 \
    --position_mask_ratio 0.33 \
    --batch_size 64 \
    --epochs 100 \
    --lr 1e-4 \
    --exp_name full_featured
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### é…ç½®æ–‡ä»¶ä¼˜å…ˆçº§

**å‘½ä»¤è¡Œå‚æ•° > config.yaml**

è¿™æ„å‘³ç€ä½ å¯ä»¥ï¼š
1. åœ¨ `config.yaml` ä¸­è®¾ç½®é»˜è®¤å€¼
2. ç”¨å‘½ä»¤è¡Œå‚æ•°å¿«é€Ÿå®éªŒä¸åŒé…ç½®
3. ä¸éœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶

### config.yaml ç»“æ„

```yaml
# æ¨¡å‹æ¶æ„
TransformerLayer_setting:
  d_model: 256
  num_heads: 8
  d_ff: 2048
  use_gated_attention: false  # å¯è¢« --use_gated_attention è¦†ç›–
  gate_type: headwise          # å¯è¢« --gate_type è¦†ç›–
  use_moe: false               # å¯è¢« --use_moe è¦†ç›–
  num_experts: 8               # å¯è¢« --num_experts è¦†ç›–
  moe_top_k: 2                 # å¯è¢« --moe_top_k è¦†ç›–

# æ‰©æ•£è®¾ç½®
diffusion:
  diffusion_steps: 1000

# è®­ç»ƒè®¾ç½®
training:
  batch_size: 64               # å¯è¢« --batch_size è¦†ç›–
  epochs: 100                  # å¯è¢« --epochs è¦†ç›–
  learning_rate: 1e-4          # å¯è¢« --lr è¦†ç›–

# é®ç½©è®¾ç½®
masking:
  enable: false                # å¯è¢« --enable_masking è¦†ç›–
  expression_mask_ratio: 0.3   # å¯è¢« --expression_mask_ratio è¦†ç›–
  position_mask_ratio: 0.33    # å¯è¢« --position_mask_ratio è¦†ç›–

# è®­ç»ƒæ¨¡å¼
training_mode: joint           # å¯è¢« --training_mode è¦†ç›–
```

### å¸¸ç”¨å‚æ•°ç»„åˆ

```bash
# ç ”ç©¶é…ç½®ï¼ˆå°æ¨¡å‹ï¼Œå¿«é€Ÿè¿­ä»£ï¼‰
python train.py --config config.yaml --batch_size 128 --epochs 50 --lr 5e-4

# ç”Ÿäº§é…ç½®ï¼ˆå¤§æ¨¡å‹ï¼Œå……åˆ†è®­ç»ƒï¼‰
python train.py --config config.yaml --batch_size 32 --epochs 200 --lr 1e-4

# å‚æ•°é«˜æ•ˆé…ç½®ï¼ˆMoEï¼‰
python train.py --config config.yaml --use_moe --num_experts 8 --moe_top_k 2

# è¡¨è¾¾èƒ½åŠ›ä¼˜å…ˆï¼ˆGated + Denseï¼‰
python train.py --config config.yaml --use_gated_attention --gate_type elementwise
```

---

## ğŸ› ï¸ å·¥å…·è„šæœ¬

### 1. compare_configs.py

æ¯”è¾ƒä¸åŒé…ç½®çš„å‚æ•°é‡ï¼š

```bash
python compare_configs.py
```

è¾“å‡ºï¼š
- 4 ç§é…ç½®ï¼ˆBaseline, Gated, MoE, Gated+MoEï¼‰
- æ€»å‚æ•°é‡ã€æ¿€æ´»å‚æ•°é‡ã€æ¿€æ´»ç‡
- FFN å±‚æ¿€æ´»ç‡ vs æ•´ä½“æ¨¡å‹æ¿€æ´»ç‡

### 2. examples.sh

äº¤äº’å¼ç¤ºä¾‹è„šæœ¬ï¼š

```bash
# äº¤äº’æ¨¡å¼
./examples.sh

# ç›´æ¥è¿è¡ŒæŸä¸ªç¤ºä¾‹
./examples.sh 1          # åŸºç¡€è®­ç»ƒ
./examples.sh gated      # Gated Attention
./examples.sh moe        # MoE
./examples.sh combined   # Gated + MoE
./examples.sh full       # å®Œæ•´é…ç½®
./examples.sh compare    # æ¯”è¾ƒé…ç½®

# è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
./examples.sh all
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: ä»€ä¹ˆæ—¶å€™ç”¨ train.pyï¼Œä»€ä¹ˆæ—¶å€™ç”¨ main.pyï¼Ÿ

**A:** 
- **ç ”ç©¶/å®éªŒ**: ç”¨ `train.py`ï¼Œå‚æ•°ç›´è§‚ï¼Œè¾“å‡ºæ¸…æ™°
- **ç”Ÿäº§/æµæ°´çº¿**: ç”¨ `python -m alphastomics.main`ï¼Œæ”¯æŒå®Œæ•´æµç¨‹

### Q2: MoE çœŸçš„èƒ½å‡å°‘è®¡ç®—å—ï¼Ÿ

**A:** 
æ˜¯çš„ï¼è™½ç„¶æ€»å‚æ•°é‡ç•¥å¢ï¼ˆ~2%ï¼‰ï¼Œä½†æ¯æ¬¡å‰å‘ä¼ æ’­åªæ¿€æ´» top_k ä¸ªä¸“å®¶ï¼š
- 4 é€‰ 2: FFN è®¡ç®—é‡å‡å°‘ 50%
- 8 é€‰ 2: FFN è®¡ç®—é‡å‡å°‘ 75%
- æ•´ä½“æ¨¡å‹è®¡ç®—é‡å‡å°‘çº¦ 10-20%ï¼ˆå–å†³äº FFN åœ¨æ¨¡å‹ä¸­çš„å æ¯”ï¼‰

### Q3: Gated Attention å’Œæ™®é€š Attention æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**A:**
- **æ™®é€š Attention**: `output = attention(Q, K, V)`
- **Gated Attention**: `output = gate * attention(Q, K, V)`
- é—¨æ§å€¼æ˜¯å¯å­¦ä¹ çš„ï¼Œå¯ä»¥åŠ¨æ€è°ƒèŠ‚æ³¨æ„åŠ›å¼ºåº¦
- Headwise: æ¯ä¸ªå¤´ä¸€ä¸ªé—¨ï¼ˆå‚æ•°å°‘ï¼‰
- Elementwise: æ¯ä¸ªä½ç½®ä¸€ä¸ªé—¨ï¼ˆè¡¨è¾¾èƒ½åŠ›å¼ºï¼‰

### Q4: å¦‚ä½•é€‰æ‹© num_experts å’Œ moe_top_kï¼Ÿ

**A:**
æ¨èé…ç½®ï¼š
- **4 é€‰ 2**: è½»é‡çº§ï¼Œé€‚åˆå°æ•°æ®é›†
- **8 é€‰ 2**: æ ‡å‡†é…ç½®ï¼Œå¹³è¡¡æ€§èƒ½å’Œæ•ˆç‡
- **16 é€‰ 4**: å¤§è§„æ¨¡æ¨¡å‹ï¼Œéœ€è¦æ›´å¤šæ•°æ®

åŸåˆ™ï¼š
- `top_k` é€šå¸¸æ˜¯ `num_experts` çš„ 1/4 åˆ° 1/2
- æ›´å¤šä¸“å®¶ = æ›´é«˜è¡¨è¾¾èƒ½åŠ›ï¼Œä½†éœ€è¦æ›´å¤šæ•°æ®é¿å…è¿‡æ‹Ÿåˆ

### Q5: å‘½ä»¤è¡Œå‚æ•°æ˜¯å¦ä¼šè¢«ä¿å­˜ï¼Ÿ

**A:**
ä½¿ç”¨ `train.py` æ—¶ï¼Œæ‰€æœ‰æœ‰æ•ˆé…ç½®ä¼šè¢«ä¿å­˜åˆ° `outputs/<exp_name>/config.yaml`ï¼ŒåŒ…æ‹¬ï¼š
- é…ç½®æ–‡ä»¶çš„åŸå§‹å€¼
- å‘½ä»¤è¡Œè¦†ç›–çš„å€¼
- æ–¹ä¾¿åç»­å¤ç°å®éªŒ

### Q6: å¦‚ä½•æ¢å¤è®­ç»ƒï¼Ÿ

**A:**
```bash
# train.py
python train.py --config config.yaml --resume outputs/my_exp/checkpoints/last.ckpt ...

# main.py
python -m alphastomics.main train --config config.yaml --resume path/to/checkpoint.ckpt
```

### Q7: å¦‚ä½•ç›‘æ§è®­ç»ƒï¼Ÿ

**A:**
AlphaSTomics ä½¿ç”¨ Weights & Biases (wandb) è¿›è¡Œå®éªŒè·Ÿè¸ªï¼š
```bash
# ç™»å½• wandb
wandb login

# è®­ç»ƒæ—¶è‡ªåŠ¨ä¸Šä¼ æ—¥å¿—
python train.py --config config.yaml ...

# è®¿é—® https://wandb.ai æŸ¥çœ‹å®éªŒ
```

### Q8: ä¸åŒè®­ç»ƒæ¨¡å¼çš„åŒºåˆ«ï¼Ÿ

**A:**
- `joint`: åŒæ—¶è®­ç»ƒè¡¨è¾¾é‡â†’ä½ç½® å’Œ ä½ç½®â†’è¡¨è¾¾é‡
- `expr_to_pos`: åªè®­ç»ƒ è¡¨è¾¾é‡â†’ä½ç½®
- `pos_to_expr`: åªè®­ç»ƒ ä½ç½®â†’è¡¨è¾¾é‡

æ¨èä½¿ç”¨ `joint`ï¼Œé™¤éæœ‰ç‰¹å®šéœ€æ±‚ã€‚

---

## ğŸ“š æ›´å¤šèµ„æº

- **è¯¦ç»†æ–‡æ¡£**: `README.MD`
- **å¿«é€Ÿå…¥é—¨**: `QUICKSTART.md`
- **æ›´æ–°æ—¥å¿—**: `CHANGELOG_MoE_Fix.md`
- **é…ç½®è¯´æ˜**: `config.yaml`ï¼ˆå†…å«è¯¦ç»†æ³¨é‡Šï¼‰
- **å‚æ•°æ¯”è¾ƒ**: è¿è¡Œ `python compare_configs.py`
- **ç¤ºä¾‹è„šæœ¬**: `./examples.sh`

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

è¯·å‚è€ƒ `LICENSE` æ–‡ä»¶ã€‚
