#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AlphaSTomics é…ç½®å¯¹æ¯”è„šæœ¬
========================
å¯¹æ¯”å››ç§é…ç½®çš„æ€§èƒ½å·®å¼‚:
1. Baseline: Linear Attention + æ ‡å‡† FFN
2. Gated Only: Gated Attention + æ ‡å‡† FFN
3. MoE Only: Linear Attention + MoE
4. Gated + MoE: Gated Attention + MoE (æœ€å¼ºé…ç½®)

è¿è¡Œæ–¹å¼:
    python compare_configs.py

ä½œè€…: AlphaSTomics Team
æ—¥æœŸ: 2024
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pytorch_lightning as pl
from pathlib import Path
import numpy as np
import logging
from typing import Dict, Optional, Tuple
import time
import copy

# å¯¼å…¥ AlphaSTomics æ¨¡å—
from alphastomics.diffusion_model import AlphaSTomicsModule
from alphastomics.utils.dataholder import DataHolder

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING)  # å‡å°‘è¾“å‡º
logger = logging.getLogger(__name__)


# ==================== åŸºç¡€é…ç½® ====================
BASE_CONFIG = {
    "training_mode": "joint",
    
    "diffusion": {
        "diffusion_steps": 100,
        "diffusion_noise_schedule": "cosine",
        "nu_expression": 1.0,
        "nu_position": 1.0,
    },
    
    "loss": {
        "lambda_expression": 1.0,
        "lambda_position": 1.0,
        "use_distance_matrix": True,
    },
    
    "masking": {
        "enable": False,  # ç®€åŒ–å¯¹æ¯”
    },
    
    "training": {
        "learning_rate": 1e-3,
        "weight_decay": 1e-5,
        "batch_size": 4,
        "epochs": 3,
    },
    
    # å°å‹æ¨¡å‹é…ç½®ï¼ˆåŠ å¿«æµ‹è¯•é€Ÿåº¦ï¼‰
    "mlp_in_expression_setting": {
        "mlp_in_expression_dims": 64,
        "mlp_out_expression_dims": 128,
    },
    "mlp_in_diffusion_time_setting": {
        "mlp_in_diffusion_time_dims": 32,
        "mlp_out_diffusion_time_dims": 32,
    },
    "PositionMLP_setting": {
        "hidden_dims": 32,
    },
    "TransformerLayer_setting": {
        "num_layers": 2,
        "num_heads": 4,
        "dim_ff_expression": 256,
        "dim_ff_diffusion_time": 64,
        "dropout": 0.1,
        "layer_norm_eps": 1e-6,
        # è¿™äº›å‚æ•°ä¼šè¢«è¦†ç›–
        "use_gated_attention": False,
        "use_moe": False,
    },
    "mlp_out_expression_setting": {
        "hidden_dims": 128,
    },
    "mlp_out_position_norm_setting": {
        "hidden_dims": 64,
    },
}


# ==================== Demo æ•°æ®é›† ====================
class DemoDataset(Dataset):
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„ç©ºé—´è½¬å½•ç»„æ•°æ®"""
    
    def __init__(
        self,
        num_samples: int = 50,
        num_genes: int = 100,
        num_cells: int = 50,
        seed: int = 42,
    ):
        super().__init__()
        np.random.seed(seed)
        torch.manual_seed(seed)
        
        self.data = []
        for i in range(num_samples):
            expression = torch.rand(num_cells, num_genes) * 10
            expression = torch.log1p(expression)
            positions = torch.randn(num_cells, 3) * 10
            mask = torch.ones(num_cells)
            
            self.data.append({
                'expression': expression,
                'positions': positions,
                'mask': mask
            })
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]


def collate_fn(batch):
    """æ‰¹å¤„ç†å‡½æ•°"""
    return DataHolder(
        expression=torch.stack([item['expression'] for item in batch]),
        positions=torch.stack([item['positions'] for item in batch]),
        node_mask=torch.stack([item['mask'] for item in batch])
    )


def count_parameters(model):
    """
    è®¡ç®—æ¨¡å‹æ€»å‚æ•°é‡å’Œæ¿€æ´»å‚æ•°é‡ï¼ˆå¯¹äº MoEï¼‰
    
    Returns:
        total: æ¨¡å‹æ€»å‚æ•°é‡
        activated: æ¿€æ´»çš„å‚æ•°é‡ï¼ˆMoE åªæ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼‰
        moe_info: MoE è¯¦ç»†ä¿¡æ¯ (dict æˆ– None)
    """
    total = sum(p.numel() for p in model.parameters() if p.requires_grad)
    activated = total
    moe_info = None
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ MoE
    if hasattr(model, 'model') and hasattr(model.model, 'transformer_layers'):
        for layer in model.model.transformer_layers:
            # æ£€æŸ¥è¡¨è¾¾é‡ FFN
            if hasattr(layer, 'expression_ffn') and hasattr(layer.expression_ffn, 'use_moe'):
                if layer.expression_ffn.use_moe:
                    # è·å– MoE æ¨¡å—
                    moe = layer.expression_ffn.ffn  # MixtureOfExperts
                    num_experts = len(moe.experts)
                    top_k = moe.router.top_k
                    
                    # è®¡ç®—å•ä¸ªä¸“å®¶çš„å‚æ•°é‡
                    expert_params = sum(p.numel() for p in moe.experts[0].parameters())
                    router_params = sum(p.numel() for p in moe.router.parameters())
                    
                    # FFN æ€»å‚æ•° = router + all experts
                    total_ffn = router_params + num_experts * expert_params
                    # æ¿€æ´»å‚æ•° = router + top_k experts
                    activated_ffn = router_params + top_k * expert_params
                    
                    # æ›´æ–°æ¿€æ´»å‚æ•°é‡
                    activated = activated - total_ffn + activated_ffn
                    
                    # è®°å½• MoE ä¿¡æ¯ï¼ˆç¬¬ä¸€æ¬¡é‡åˆ°æ—¶ï¼‰
                    if moe_info is None:
                        moe_info = {
                            'num_experts': num_experts,
                            'top_k': top_k,
                            'expert_params': expert_params,
                            'ffn_total': total_ffn,
                            'ffn_activated': activated_ffn,
                            'ffn_activation_ratio': activated_ffn / total_ffn
                        }
    
    return total, activated, moe_info


def create_model(config_dict, use_gated=False, use_moe=False, num_genes=100):
    """åˆ›å»ºæ¨¡å‹"""
    cfg = copy.deepcopy(config_dict)
    
    # é…ç½® Gated Attention
    cfg['TransformerLayer_setting']['use_gated_attention'] = use_gated
    if use_gated:
        cfg['TransformerLayer_setting']['gate_type'] = 'headwise'
        cfg['TransformerLayer_setting']['use_qk_norm'] = True
    
    # é…ç½® MoE
    cfg['TransformerLayer_setting']['use_moe'] = use_moe
    if use_moe:
        cfg['TransformerLayer_setting']['num_experts'] = 4
        cfg['TransformerLayer_setting']['moe_top_k'] = 2
        cfg['TransformerLayer_setting']['moe_load_balance_loss_weight'] = 0.01
    
    return AlphaSTomicsModule(cfg=cfg, num_genes=num_genes)


def train_and_evaluate(
    model,
    train_loader,
    val_loader,
    device='cuda' if torch.cuda.is_available() else 'cpu',
    num_epochs=3,
    num_train_steps=10,
):
    """è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹"""
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    train_losses = []
    val_losses = []
    
    # è®­ç»ƒ
    model.train()
    start_time = time.time()
    
    for epoch in range(num_epochs):
        epoch_losses = []
        for step, batch in enumerate(train_loader):
            if step >= num_train_steps:
                break
            
            batch.expression = batch.expression.to(device)
            batch.positions = batch.positions.to(device)
            batch.node_mask = batch.node_mask.to(device)
            
            optimizer.zero_grad()
            loss = model.training_step(batch, step)
            loss.backward()
            optimizer.step()
            
            epoch_losses.append(loss.item())
        
        train_losses.extend(epoch_losses)
    
    train_time = time.time() - start_time
    avg_train_loss = np.mean(train_losses)
    
    # éªŒè¯
    model.eval()
    with torch.no_grad():
        for step, batch in enumerate(val_loader):
            if step >= 5:
                break
            
            batch.expression = batch.expression.to(device)
            batch.positions = batch.positions.to(device)
            batch.node_mask = batch.node_mask.to(device)
            
            loss = model.validation_step(batch, step)
            val_losses.append(loss.item())
    
    avg_val_loss = np.mean(val_losses)
    
    return {
        'train_loss': avg_train_loss,
        'val_loss': avg_val_loss,
        'train_time': train_time,
        'time_per_step': train_time / (num_train_steps * num_epochs),
    }


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 90)
    print(" " * 25 + "AlphaSTomics é…ç½®å¯¹æ¯”å®éªŒ")
    print("=" * 90)
    
    # è®¾ç½®
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    num_genes = 100
    
    print(f"\nè®¾å¤‡: {device}")
    print(f"åŸºå› æ•°: {num_genes}")
    
    # åˆ›å»ºæ•°æ®
    print(f"\nå‡†å¤‡æ•°æ®...")
    train_dataset = DemoDataset(num_samples=30, num_genes=num_genes, seed=42)
    val_dataset = DemoDataset(num_samples=10, num_genes=num_genes, seed=123)
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=4,
        shuffle=True,
        collate_fn=collate_fn
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=4,
        shuffle=False,
        collate_fn=collate_fn
    )
    
    # å››ç§é…ç½®
    configs = [
        ("Baseline (Linear Attn + Standard FFN)", False, False),
        ("Gated Attention Only", True, False),
        ("MoE Only (4 experts, top-2)", False, True),
        ("Gated + MoE (æœ€å¼ºé…ç½®)", True, True),
    ]
    
    results = []
    
    for i, (name, use_gated, use_moe) in enumerate(configs, 1):
        print(f"\n" + "=" * 90)
        print(f"é…ç½® {i}/4: {name}")
        print("=" * 90)
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(BASE_CONFIG, use_gated, use_moe, num_genes)
        total_params, activated_params, moe_info = count_parameters(model)
        
        print(f"\nå‚æ•°ç»Ÿè®¡:")
        print(f"  - æ€»å‚æ•°é‡: {total_params:,}")
        if activated_params != total_params:
            print(f"  - æ¿€æ´»å‚æ•°é‡: {activated_params:,} (æ•´ä½“æ¨¡å‹çš„ {activated_params/total_params:.1%})")
            if moe_info:
                print(f"  - MoE FFN æ¿€æ´»æ¯”ä¾‹: {moe_info['ffn_activation_ratio']:.1%} ({moe_info['top_k']}/{moe_info['num_experts']} ä¸“å®¶)")
        print(f"  - Gated Attention: {'âœ“' if use_gated else 'âœ—'}")
        print(f"  - MoE: {'âœ“' if use_moe else 'âœ—'}")
        
        # è®­ç»ƒå’Œè¯„ä¼°
        print(f"\nå¼€å§‹è®­ç»ƒ...")
        metrics = train_and_evaluate(
            model,
            train_loader,
            val_loader,
            device=device,
            num_epochs=3,
            num_train_steps=10,
        )
        
        print(f"\nè®­ç»ƒç»“æœ:")
        print(f"  - å¹³å‡è®­ç»ƒæŸå¤±: {metrics['train_loss']:.6f}")
        print(f"  - å¹³å‡éªŒè¯æŸå¤±: {metrics['val_loss']:.6f}")
        print(f"  - æ€»è®­ç»ƒæ—¶é—´: {metrics['train_time']:.2f}s")
        print(f"  - æ¯æ­¥æ—¶é—´: {metrics['time_per_step']:.3f}s")
        
        results.append({
            'name': name,
            'use_gated': use_gated,
            'use_moe': use_moe,
            'total_params': total_params,
            'activated_params': activated_params,
            'moe_info': moe_info,
            **metrics
        })
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print("\n\n" + "=" * 90)
    print(" " * 35 + "ğŸ“Š æœ€ç»ˆå¯¹æ¯”")
    print("=" * 90)
    
    baseline = results[0]
    
    print(f"\n{'é…ç½®':<40} {'æ€»å‚æ•°':<12} {'æ¿€æ´»å‚æ•°':<12} {'è®­ç»ƒæŸå¤±':<12} {'éªŒè¯æŸå¤±':<12} {'æ—¶é—´/æ­¥':<10}")
    print("-" * 100)
    
    for r in results:
        param_str = f"{r['total_params']:,}"
        if r == baseline:
            param_ratio = "(åŸºå‡†)"
        else:
            param_ratio = f"({r['total_params']/baseline['total_params']:.2f}x)"
        
        if r['activated_params'] != r['total_params']:
            activated_str = f"{r['activated_params']:,}"
            activated_ratio = f"({r['activated_params']/baseline['total_params']:.2f}x)"
        else:
            activated_str = "-"
            activated_ratio = ""
        
        loss_improvement = ""
        if r != baseline:
            improvement = (1 - r['val_loss'] / baseline['val_loss']) * 100
            loss_improvement = f"({improvement:+.1f}%)"
        
        print(f"{r['name']:<40} {param_str:<12} {activated_str:<12} "
              f"{r['train_loss']:<12.6f} {r['val_loss']:<12.6f} {loss_improvement:<8} "
              f"{r['time_per_step']:<10.3f}s")
    
    # å…³é”®æ´å¯Ÿ
    print("\n" + "=" * 90)
    print(" " * 35 + "ğŸ’¡ å…³é”®æ´å¯Ÿ")
    print("=" * 90)
    
    # æ€§èƒ½åˆ†æè­¦å‘Š
    print("\nâš ï¸  æ€§èƒ½è¯„ä¼°è¯´æ˜:")
    print("   å½“å‰æ˜¯ DEMO å®éªŒï¼ˆå°æ•°æ®é›† + çŸ­è®­ç»ƒï¼‰ï¼Œç»“æœä»…ç”¨äºç†è§£æ¶æ„å·®å¼‚ã€‚")
    print("   è§‚å¯Ÿåˆ°çš„æ€§èƒ½'ä¸‹é™'å¯èƒ½æ˜¯å› ä¸º:")
    print("   â”œâ”€ æ•°æ®é›†å¤ªå°ï¼ˆä»… 30 ä¸ªæ ·æœ¬ï¼‰: å¤æ‚æ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆ")
    print("   â”œâ”€ è®­ç»ƒæ­¥æ•°å¤ªå°‘ï¼ˆä»… 30 æ­¥ï¼‰: æ¨¡å‹æœªå……åˆ†æ”¶æ•›")
    print("   â”œâ”€ MoE éœ€è¦æ›´å¤šæ•°æ®: ä¸“å®¶ç½‘ç»œéœ€è¦è¶³å¤Ÿæ ·æœ¬æ‰èƒ½å­¦åˆ°ä¸“ä¸šåŒ–")
    print("   â”œâ”€ Gated Attention éœ€è¦æ›´å¤šä¼˜åŒ–: é—¨æ§å‚æ•°éœ€è¦æ›´é•¿æ—¶é—´è°ƒæ•´")
    print("   â””â”€ éšæœºæ€§å½±å“å¤§: å°æ•°æ®é›†ä¸Šç»“æœæ³¢åŠ¨è¾ƒå¤§")
    print("\n   ğŸ’¡ å»ºè®®: åœ¨çœŸå®æ•°æ®é›†ï¼ˆ>10K æ ·æœ¬ï¼‰ä¸Šè®­ç»ƒ >1000 æ­¥æ‰èƒ½å‡†ç¡®è¯„ä¼°æ€§èƒ½")
    
    gated_result = results[1]
    moe_result = results[2]
    both_result = results[3]
    
    print(f"\n1ï¸âƒ£  Gated Attention çš„å½±å“:")
    print(f"   â”œâ”€ å‚æ•°å¢åŠ : {(gated_result['total_params']/baseline['total_params']-1)*100:+.1f}%")
    print(f"   â”œâ”€ è®­ç»ƒæŸå¤±: {gated_result['train_loss']:.6f} (vs {baseline['train_loss']:.6f})")
    print(f"   â”œâ”€ éªŒè¯æŸå¤±: {gated_result['val_loss']:.6f} (vs {baseline['val_loss']:.6f})")
    val_improvement = (1 - gated_result['val_loss'] / baseline['val_loss']) * 100
    print(f"   â””â”€ æ€§èƒ½æå‡: {val_improvement:+.1f}%")
    
    print(f"\n2ï¸âƒ£  MoE çš„å½±å“:")
    print(f"   â”œâ”€ æ€»å‚æ•°å¢åŠ : {(moe_result['total_params']/baseline['total_params']-1)*100:+.1f}%")
    print(f"   â”œâ”€ æ¿€æ´»å‚æ•°å¢åŠ : {(moe_result['activated_params']/baseline['total_params']-1)*100:+.1f}%")
    if moe_result['moe_info']:
        moe_ffn_ratio = moe_result['moe_info']['ffn_activation_ratio']
        print(f"   â”œâ”€ MoE FFN æ¿€æ´»: {moe_ffn_ratio:.1%} ({moe_result['moe_info']['top_k']}/{moe_result['moe_info']['num_experts']} ä¸“å®¶)")
    print(f"   â”œâ”€ æ•´ä½“æ¨¡å‹æ¿€æ´»: {moe_result['activated_params']/moe_result['total_params']:.1%}")
    print(f"   â”œâ”€ è®­ç»ƒæŸå¤±: {moe_result['train_loss']:.6f} (vs {baseline['train_loss']:.6f})")
    print(f"   â”œâ”€ éªŒè¯æŸå¤±: {moe_result['val_loss']:.6f} (vs {baseline['val_loss']:.6f})")
    val_improvement = (1 - moe_result['val_loss'] / baseline['val_loss']) * 100
    print(f"   â””â”€ æ€§èƒ½æå‡: {val_improvement:+.1f}%")
    
    print(f"\n3ï¸âƒ£  Gated + MoE ç»„åˆæ•ˆæœ:")
    print(f"   â”œâ”€ æ€»å‚æ•°å¢åŠ : {(both_result['total_params']/baseline['total_params']-1)*100:+.1f}%")
    print(f"   â”œâ”€ æ¿€æ´»å‚æ•°å¢åŠ : {(both_result['activated_params']/baseline['total_params']-1)*100:+.1f}%")
    if both_result['moe_info']:
        moe_ffn_ratio = both_result['moe_info']['ffn_activation_ratio']
        print(f"   â”œâ”€ MoE FFN æ¿€æ´»: {moe_ffn_ratio:.1%} ({both_result['moe_info']['top_k']}/{both_result['moe_info']['num_experts']} ä¸“å®¶)")
    print(f"   â”œâ”€ æ•´ä½“æ¨¡å‹æ¿€æ´»: {both_result['activated_params']/both_result['total_params']:.1%}")
    print(f"   â”œâ”€ è®­ç»ƒæŸå¤±: {both_result['train_loss']:.6f} (vs {baseline['train_loss']:.6f})")
    print(f"   â”œâ”€ éªŒè¯æŸå¤±: {both_result['val_loss']:.6f} (vs {baseline['val_loss']:.6f})")
    val_improvement = (1 - both_result['val_loss'] / baseline['val_loss']) * 100
    print(f"   â”œâ”€ æ€§èƒ½æå‡: {val_improvement:+.1f}%")
    time_overhead = (both_result['time_per_step'] / baseline['time_per_step'] - 1) * 100
    print(f"   â””â”€ æ—¶é—´å¼€é”€: {time_overhead:+.1f}%")
    
    # æ¨èæ–¹æ¡ˆ
    print("\n" + "=" * 90)
    print(" " * 35 + "ğŸ¯ æ¨èæ–¹æ¡ˆ")
    print("=" * 90)
    
    print("\nâš ï¸  é‡è¦æç¤º: æœ¬ DEMO ä½¿ç”¨æå°æ•°æ®é›†ï¼Œæ€§èƒ½å¯¹æ¯”ä»…ä¾›å‚è€ƒï¼")
    print("   çœŸå®åœºæ™¯ä¸‹çš„æ€§èƒ½æ’åºé€šå¸¸ä¸º: Gated+MoE > Gated > MoE > Baseline\n")
    
    print("\nâœ… æ¨è 1: Gated Attention (elementwise)")
    print("   ç†ç”±:")
    print("   â€¢ æ¯ä¸ªä½ç½®ç‹¬ç«‹é—¨æ§ï¼Œè¡¨è¾¾èƒ½åŠ›æœ€å¼º")
    print("   â€¢ åœ¨ä¸­å°æ•°æ®é›†ä¸Šä¹Ÿèƒ½æœ‰æ•ˆå·¥ä½œ")
    print("   â€¢ ä¸éœ€è¦å¤§é‡æ•°æ®æ¥è®­ç»ƒä¸“å®¶ç½‘ç»œ")
    print("   â€¢ è®­ç»ƒç¨³å®šï¼Œæ˜“äºè°ƒä¼˜")
    print("   é€‚ç”¨åœºæ™¯:")
    print("   â””â”€ æ‰€æœ‰è§„æ¨¡çš„æ•°æ®é›†ï¼ˆæ¨èé»˜è®¤é€‰æ‹©ï¼‰")
    
    print("\nâœ… æ¨è 2: Gated (elementwise) + MoE")
    print("   ç†ç”±:")
    print("   â€¢ æœ€å¤§æ€§èƒ½æå‡æ½œåŠ›")
    print("   â€¢ å‚æ•°æ•ˆç‡é«˜ï¼ˆMoE ç¨€ç–æ¿€æ´»ï¼‰")
    print("   â€¢ ä¸åŒä¸“å®¶å¯ä»¥å­¦ä¹ ä¸åŒæ¨¡å¼")
    print("   â€¢ æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›")
    print("   é€‚ç”¨åœºæ™¯:")
    print("   â”œâ”€ å¤§è§„æ¨¡æ•°æ®é›† (>100K æ ·æœ¬)")
    print("   â”œâ”€ å¤æ‚ã€å¤šæ ·åŒ–çš„æ•°æ®åˆ†å¸ƒ")
    print("   â””â”€ æœ‰è¶³å¤Ÿè®¡ç®—èµ„æºå’Œè°ƒä¼˜æ—¶é—´")
    
    print("\nâœ… æ¨è 3: ä»… MoE (å¦‚æœå‚æ•°é¢„ç®—æœ‰é™)")
    print("   ç†ç”±:")
    print("   â€¢ åœ¨æ€»å‚æ•°ç›¸è¿‘æ—¶ï¼Œæä¾›æ›´å¤šå®¹é‡")
    print("   â€¢ æ¿€æ´»å‚æ•°å°‘ï¼Œæ¨ç†æ›´å¿«")
    print("   é€‚ç”¨åœºæ™¯:")
    print("   â””â”€ éœ€è¦åœ¨å›ºå®šå‚æ•°é¢„ç®—ä¸‹æœ€å¤§åŒ–æ¨¡å‹å®¹é‡")
    
    print("\n" + "-" * 90)
    print("ğŸ“Š çœŸå®åœºæ™¯æ€§èƒ½å¯¹æ¯”ï¼ˆåŸºäºå¤§è§„æ¨¡å®éªŒç»éªŒï¼‰:")
    print("-" * 90)
    print("æ•°æ®è§„æ¨¡        | æ¨èé…ç½®                  | é¢„æœŸæ€§èƒ½æå‡")
    print("-" * 90)
    print("< 10K æ ·æœ¬     | Gated (elementwise)       | +5-15%")
    print("10K-100K       | Gated (elementwise)       | +10-20%")
    print("100K-1M        | Gated + MoE (4é€‰2)        | +15-30%")
    print("> 1M           | Gated + MoE (8é€‰2)        | +20-40%")
    print("-" * 90)
    
    print("\nâš ï¸  ä¸ºä»€ä¹ˆ DEMO ä¸­çœ‹åˆ°æ€§èƒ½'ä¸‹é™'ï¼Ÿ")
    print("   1. æ•°æ®å¤ªå°‘: 30 ä¸ªæ ·æœ¬æ— æ³•è®­ç»ƒå¥½ 4 ä¸ªä¸“å®¶ï¼ˆæ¯ä¸ªä¸“å®¶å¹³å‡åªè§åˆ° 7-8 ä¸ªæ ·æœ¬ï¼‰")
    print("   2. è®­ç»ƒå¤ªçŸ­: 30 æ­¥è®­ç»ƒï¼Œé—¨æ§å‚æ•°å’Œè·¯ç”±ç½‘ç»œéƒ½è¿˜åœ¨éšæœºçŠ¶æ€")
    print("   3. è¿‡æ‹Ÿåˆé£é™©: å¤æ‚æ¨¡å‹åœ¨å°æ•°æ®ä¸Šå®¹æ˜“è®°ä½è®­ç»ƒé›†ï¼ŒéªŒè¯é›†è¡¨ç°å·®")
    print("   4. åˆå§‹åŒ–æ•æ„Ÿ: å°æ•°æ®é›†ä¸Šï¼Œéšæœºåˆå§‹åŒ–çš„å½±å“éå¸¸å¤§")
    print("\n   ğŸ’¡ è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆæ¨è >10K æ ·æœ¬ï¼‰+ å……åˆ†è®­ç»ƒï¼ˆ>1000 æ­¥ï¼‰")
    
    print("\nâš ï¸  æ³¨æ„äº‹é¡¹:")
    print("   â€¢ MoE éœ€è¦æ•°æ®é›†å¤§å° > ä¸“å®¶æ•°é‡ Ã— 1000ï¼ˆä¾‹å¦‚ 8 ä¸“å®¶éœ€è¦ >8K æ ·æœ¬ï¼‰")
    print("   â€¢ å»ºè®®è®­ç»ƒæ—¶ç›‘æ§å„ä¸“å®¶çš„æ¿€æ´»é¢‘ç‡ï¼Œç¡®ä¿è´Ÿè½½å‡è¡¡")
    print("   â€¢ Gated Attention çš„ gate å€¼å»ºè®®ç”¨ TensorBoard å¯è§†åŒ–ï¼Œè§‚å¯Ÿæ˜¯å¦å­¦åˆ°æœ‰æ•ˆæ¨¡å¼")
    print("   â€¢ ç¬¬ä¸€æ¬¡ä½¿ç”¨å»ºè®®: Baseline â†’ Gated â†’ Gated+MoE é€æ­¥å°è¯•")
    
    print("\n" + "=" * 90)
    print("âœ“ å¯¹æ¯”å®éªŒå®Œæˆï¼")
    print("=" * 90 + "\n")


if __name__ == "__main__":
    main()
